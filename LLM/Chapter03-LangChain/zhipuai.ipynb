{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-03T10:17:35.111407600Z",
     "start_time": "2024-04-03T10:17:35.093437600Z"
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "yaml_file = \"../../key/key.yaml\"\n",
    "with open(yaml_file, 'r') as file:\n",
    "    data_key = yaml.safe_load(file)\n",
    "\n",
    "zhipuai_info = data_key.get(\"zhipuai\", {})\n",
    "zhipuai_api_key = zhipuai_info.get('APIKey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 14\u001B[0m\n\u001B[0;32m      4\u001B[0m chat \u001B[38;5;241m=\u001B[39m ChatZhipuAI(\n\u001B[0;32m      5\u001B[0m     api_key\u001B[38;5;241m=\u001B[39mzhipuai_api_key,\n\u001B[0;32m      6\u001B[0m     model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchatglm_pro\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      7\u001B[0m     temperature\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m,\n\u001B[0;32m      8\u001B[0m )\n\u001B[0;32m      9\u001B[0m messages \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     10\u001B[0m     AIMessage(content\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHi.\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m     11\u001B[0m     SystemMessage(content\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYour role is a poet.\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m     12\u001B[0m     HumanMessage(content\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWrite a short poem about AI in four lines.\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[0;32m     13\u001B[0m ]\n\u001B[1;32m---> 14\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mchat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(response\u001B[38;5;241m.\u001B[39mcontent)\n",
      "File \u001B[1;32mD:\\systemEnvironment\\Anaconda3\\envs\\llm\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:145\u001B[0m, in \u001B[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    143\u001B[0m     warned \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    144\u001B[0m     emit_warning()\n\u001B[1;32m--> 145\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m wrapped(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\systemEnvironment\\Anaconda3\\envs\\llm\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:798\u001B[0m, in \u001B[0;36mBaseChatModel.__call__\u001B[1;34m(self, messages, stop, callbacks, **kwargs)\u001B[0m\n\u001B[0;32m    790\u001B[0m \u001B[38;5;129m@deprecated\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0.1.7\u001B[39m\u001B[38;5;124m\"\u001B[39m, alternative\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minvoke\u001B[39m\u001B[38;5;124m\"\u001B[39m, removal\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0.2.0\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    791\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\n\u001B[0;32m    792\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    796\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    797\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m BaseMessage:\n\u001B[1;32m--> 798\u001B[0m     generation \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerate(\n\u001B[0;32m    799\u001B[0m         [messages], stop\u001B[38;5;241m=\u001B[39mstop, callbacks\u001B[38;5;241m=\u001B[39mcallbacks, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    800\u001B[0m     )\u001B[38;5;241m.\u001B[39mgenerations[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    801\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(generation, ChatGeneration):\n\u001B[0;32m    802\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m generation\u001B[38;5;241m.\u001B[39mmessage\n",
      "File \u001B[1;32mD:\\systemEnvironment\\Anaconda3\\envs\\llm\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:415\u001B[0m, in \u001B[0;36mBaseChatModel.generate\u001B[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[0m\n\u001B[0;32m    413\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n\u001B[0;32m    414\u001B[0m             run_managers[i]\u001B[38;5;241m.\u001B[39mon_llm_error(e, response\u001B[38;5;241m=\u001B[39mLLMResult(generations\u001B[38;5;241m=\u001B[39m[]))\n\u001B[1;32m--> 415\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m    416\u001B[0m flattened_outputs \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    417\u001B[0m     LLMResult(generations\u001B[38;5;241m=\u001B[39m[res\u001B[38;5;241m.\u001B[39mgenerations], llm_output\u001B[38;5;241m=\u001B[39mres\u001B[38;5;241m.\u001B[39mllm_output)  \u001B[38;5;66;03m# type: ignore[list-item]\u001B[39;00m\n\u001B[0;32m    418\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m results\n\u001B[0;32m    419\u001B[0m ]\n\u001B[0;32m    420\u001B[0m llm_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_combine_llm_outputs([res\u001B[38;5;241m.\u001B[39mllm_output \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m results])\n",
      "File \u001B[1;32mD:\\systemEnvironment\\Anaconda3\\envs\\llm\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:405\u001B[0m, in \u001B[0;36mBaseChatModel.generate\u001B[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[0m\n\u001B[0;32m    402\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(messages):\n\u001B[0;32m    403\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    404\u001B[0m         results\u001B[38;5;241m.\u001B[39mappend(\n\u001B[1;32m--> 405\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate_with_cache(\n\u001B[0;32m    406\u001B[0m                 m,\n\u001B[0;32m    407\u001B[0m                 stop\u001B[38;5;241m=\u001B[39mstop,\n\u001B[0;32m    408\u001B[0m                 run_manager\u001B[38;5;241m=\u001B[39mrun_managers[i] \u001B[38;5;28;01mif\u001B[39;00m run_managers \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    409\u001B[0m                 \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    410\u001B[0m             )\n\u001B[0;32m    411\u001B[0m         )\n\u001B[0;32m    412\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    413\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "File \u001B[1;32mD:\\systemEnvironment\\Anaconda3\\envs\\llm\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:624\u001B[0m, in \u001B[0;36mBaseChatModel._generate_with_cache\u001B[1;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[0;32m    622\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    623\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39msignature(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate)\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 624\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(\n\u001B[0;32m    625\u001B[0m             messages, stop\u001B[38;5;241m=\u001B[39mstop, run_manager\u001B[38;5;241m=\u001B[39mrun_manager, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    626\u001B[0m         )\n\u001B[0;32m    627\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    628\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(messages, stop\u001B[38;5;241m=\u001B[39mstop, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\systemEnvironment\\Anaconda3\\envs\\llm\\lib\\site-packages\\langchain_community\\chat_models\\zhipuai.py:267\u001B[0m, in \u001B[0;36mChatZhipuAI._generate\u001B[1;34m(self, messages, stop, run_manager, stream, **kwargs)\u001B[0m\n\u001B[0;32m    264\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m should_stream:\n\u001B[0;32m    265\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minvoke(prompt)\n\u001B[1;32m--> 267\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mresponse\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcode\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m200\u001B[39m:\n\u001B[0;32m    268\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(response)\n\u001B[0;32m    270\u001B[0m     content \u001B[38;5;241m=\u001B[39m response[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchoices\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "\u001B[1;31mTypeError\u001B[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "chat = ChatZhipuAI(\n",
    "    api_key=zhipuai_api_key,\n",
    "    model=\"glm-4\",\n",
    "    temperature=0.5,\n",
    ")\n",
    "messages = [\n",
    "    AIMessage(content=\"Hi.\"),\n",
    "    SystemMessage(content=\"Your role is a poet.\"),\n",
    "    HumanMessage(content=\"Write a short poem about AI in four lines.\"),\n",
    "]\n",
    "response = chat(messages)\n",
    "print(response.content)  # Displays the AI-generated poem\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T10:22:37.489180500Z",
     "start_time": "2024-04-03T10:22:37.426123500Z"
    }
   },
   "id": "677b93b0d3100b4d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bc3a068912011b1b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cc45bcd8e123014e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ac7ad795b1718bf0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8e5e5c78598237d8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b879a60482614c39"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bbda5f8dea935abf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a41481a448d0ef2e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "64af41bfbb1fe114"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cc1911fecb505655"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "40ea61a5b56ca293"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3c4a133d0216aa9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "98c514495b4bfae"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
